{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_selected = pd.read_csv('data/rusentiment/rusentiment_preselected_posts.csv')\n",
    "df_random = pd.read_csv('data/rusentiment/rusentiment_random_posts.csv')\n",
    "df_test = pd.read_csv('data/rusentiment/rusentiment_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.concat((df_selected, df_random))#available other ways to concatenate\n",
    "df_train.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ufal.udpipe import Model, Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Original code https://github.com/akutuzov/webvectors/blob/master/preprocessing/rus_preprocessing_udpipe.py\n",
    "\n",
    "def tag_ud(pipeline, text='Текст нужно передать функции в виде строки!', pos=True):\n",
    "    # если частеречные тэги не нужны (например, их нет в модели), выставьте pos=False\n",
    "    # в этом случае на выход будут поданы только леммы\n",
    "\n",
    "    # обрабатываем текст, получаем результат в формате conllu:\n",
    "    processed = pipeline.process(text)\n",
    "\n",
    "    # пропускаем строки со служебной информацией:\n",
    "    content = [l for l in processed.split('\\n') if not l.startswith('#')]\n",
    "\n",
    "    # извлекаем из обработанного текста лемму и тэг\n",
    "    tagged = [w.split('\\t')[2].lower() + '_' + w.split('\\t')[3] for w in content if w]\n",
    "\n",
    "    tagged_propn = []\n",
    "    propn = []\n",
    "    for t in tagged:\n",
    "        if t.endswith('PROPN'):\n",
    "            if propn:\n",
    "                propn.append(t)\n",
    "            else:\n",
    "                propn = [t]\n",
    "        elif t.endswith('PUNCT'):\n",
    "            propn = []\n",
    "            continue  # я здесь пропускаю знаки препинания, но вы можете поступить по-другому\n",
    "        else:\n",
    "            if len(propn) > 1:\n",
    "                name = '::'.join([x.split('_')[0] for x in propn]) + '_PROPN'\n",
    "                tagged_propn.append(name)\n",
    "            elif len(propn) == 1:\n",
    "                tagged_propn.append(propn[0])\n",
    "            tagged_propn.append(t)\n",
    "            propn = []\n",
    "    if not pos:\n",
    "        tagged_propn = [t.split('_')[0] for t in tagged_propn]\n",
    "    return tagged_propn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model.load('udpipe_syntagrus.model')\n",
    "process_pipeline = Pipeline(model, 'tokenize', Pipeline.DEFAULT, Pipeline.DEFAULT, 'conllu') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['lemmatized_tokens'] = df_train.apply(lambda x: tag_ud(process_pipeline, x['text'], pos=False), axis=1)\n",
    "df_test['lemmatized_tokens'] = df_test.apply(lambda x: tag_ud(process_pipeline, x['text'], pos=False), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = preprocessing.LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['lemmatized_text'] = df_train['lemmatized_tokens'].str.join(' ')\n",
    "df_test['lemmatized_text'] = df_test['lemmatized_tokens'].str.join(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_train['lemmatized_text'].values\n",
    "X_test = df_test['lemmatized_text'].values\n",
    "\n",
    "Y_train = le.fit_transform(df_train['label'].values)\n",
    "Y_test = le.transform(df_test['label'].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(ngram_range=(1,1))\n",
    "X_train_vect = vectorizer.fit_transform(X_train)\n",
    "X_test_vect = vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_split, X_valid, Y_train_split, Y_valid= train_test_split(X_train_vect, Y_train, test_size=0.33, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train = lgb.Dataset(X_train_split, label = Y_train_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_valid = lgb.Dataset(X_valid, label = Y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = dataset_train.create_valid(dataset_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metric functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, precision_score, recall_score, confusion_matrix\n",
    "\n",
    "def score_model(y_pred, y_true):\n",
    "    average = 'weighted'\n",
    "    f1 = f1_score(y_true, y_pred, average=average)\n",
    "    precision = precision_score(y_true, y_pred, average=average)\n",
    "    recall = recall_score(y_true, y_pred, average=average)\n",
    "    return f1, precision, recall\n",
    "\n",
    "def check_model(y_pred,Y_test):\n",
    "    f1, precision, recall = score_model(y_pred,Y_test)\n",
    "    print(f'Precision: {precision:.4f}')\n",
    "    print(f'Recall: {recall:.4f}')\n",
    "    print(f'f1-score: {f1:.4f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Default gradient-boosting classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_lgbc = lgb.LGBMClassifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fitting with validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\tvalid_0's multi_logloss: 1.56036\n",
      "[2]\tvalid_0's multi_logloss: 1.5197\n",
      "[3]\tvalid_0's multi_logloss: 1.48501\n",
      "[4]\tvalid_0's multi_logloss: 1.4553\n",
      "[5]\tvalid_0's multi_logloss: 1.42921\n",
      "[6]\tvalid_0's multi_logloss: 1.4064\n",
      "[7]\tvalid_0's multi_logloss: 1.38647\n",
      "[8]\tvalid_0's multi_logloss: 1.36835\n",
      "[9]\tvalid_0's multi_logloss: 1.35248\n",
      "[10]\tvalid_0's multi_logloss: 1.33785\n",
      "[11]\tvalid_0's multi_logloss: 1.32524\n",
      "[12]\tvalid_0's multi_logloss: 1.31393\n",
      "[13]\tvalid_0's multi_logloss: 1.30379\n",
      "[14]\tvalid_0's multi_logloss: 1.29416\n",
      "[15]\tvalid_0's multi_logloss: 1.28528\n",
      "[16]\tvalid_0's multi_logloss: 1.27744\n",
      "[17]\tvalid_0's multi_logloss: 1.26994\n",
      "[18]\tvalid_0's multi_logloss: 1.26333\n",
      "[19]\tvalid_0's multi_logloss: 1.25698\n",
      "[20]\tvalid_0's multi_logloss: 1.25123\n",
      "[21]\tvalid_0's multi_logloss: 1.24566\n",
      "[22]\tvalid_0's multi_logloss: 1.24062\n",
      "[23]\tvalid_0's multi_logloss: 1.23574\n",
      "[24]\tvalid_0's multi_logloss: 1.23159\n",
      "[25]\tvalid_0's multi_logloss: 1.22725\n",
      "[26]\tvalid_0's multi_logloss: 1.22349\n",
      "[27]\tvalid_0's multi_logloss: 1.21971\n",
      "[28]\tvalid_0's multi_logloss: 1.21609\n",
      "[29]\tvalid_0's multi_logloss: 1.21272\n",
      "[30]\tvalid_0's multi_logloss: 1.20957\n",
      "[31]\tvalid_0's multi_logloss: 1.20656\n",
      "[32]\tvalid_0's multi_logloss: 1.20344\n",
      "[33]\tvalid_0's multi_logloss: 1.20083\n",
      "[34]\tvalid_0's multi_logloss: 1.19832\n",
      "[35]\tvalid_0's multi_logloss: 1.19567\n",
      "[36]\tvalid_0's multi_logloss: 1.1932\n",
      "[37]\tvalid_0's multi_logloss: 1.1909\n",
      "[38]\tvalid_0's multi_logloss: 1.18853\n",
      "[39]\tvalid_0's multi_logloss: 1.18645\n",
      "[40]\tvalid_0's multi_logloss: 1.18436\n",
      "[41]\tvalid_0's multi_logloss: 1.18251\n",
      "[42]\tvalid_0's multi_logloss: 1.1805\n",
      "[43]\tvalid_0's multi_logloss: 1.17869\n",
      "[44]\tvalid_0's multi_logloss: 1.17685\n",
      "[45]\tvalid_0's multi_logloss: 1.17546\n",
      "[46]\tvalid_0's multi_logloss: 1.17433\n",
      "[47]\tvalid_0's multi_logloss: 1.17292\n",
      "[48]\tvalid_0's multi_logloss: 1.17137\n",
      "[49]\tvalid_0's multi_logloss: 1.17008\n",
      "[50]\tvalid_0's multi_logloss: 1.16876\n",
      "[51]\tvalid_0's multi_logloss: 1.16766\n",
      "[52]\tvalid_0's multi_logloss: 1.1665\n",
      "[53]\tvalid_0's multi_logloss: 1.16549\n",
      "[54]\tvalid_0's multi_logloss: 1.16419\n",
      "[55]\tvalid_0's multi_logloss: 1.16281\n",
      "[56]\tvalid_0's multi_logloss: 1.16185\n",
      "[57]\tvalid_0's multi_logloss: 1.1607\n",
      "[58]\tvalid_0's multi_logloss: 1.15979\n",
      "[59]\tvalid_0's multi_logloss: 1.159\n",
      "[60]\tvalid_0's multi_logloss: 1.158\n",
      "[61]\tvalid_0's multi_logloss: 1.1569\n",
      "[62]\tvalid_0's multi_logloss: 1.15594\n",
      "[63]\tvalid_0's multi_logloss: 1.15494\n",
      "[64]\tvalid_0's multi_logloss: 1.15399\n",
      "[65]\tvalid_0's multi_logloss: 1.15284\n",
      "[66]\tvalid_0's multi_logloss: 1.15198\n",
      "[67]\tvalid_0's multi_logloss: 1.15125\n",
      "[68]\tvalid_0's multi_logloss: 1.15053\n",
      "[69]\tvalid_0's multi_logloss: 1.14972\n",
      "[70]\tvalid_0's multi_logloss: 1.14883\n",
      "[71]\tvalid_0's multi_logloss: 1.14821\n",
      "[72]\tvalid_0's multi_logloss: 1.1475\n",
      "[73]\tvalid_0's multi_logloss: 1.14689\n",
      "[74]\tvalid_0's multi_logloss: 1.14617\n",
      "[75]\tvalid_0's multi_logloss: 1.14553\n",
      "[76]\tvalid_0's multi_logloss: 1.145\n",
      "[77]\tvalid_0's multi_logloss: 1.14456\n",
      "[78]\tvalid_0's multi_logloss: 1.14419\n",
      "[79]\tvalid_0's multi_logloss: 1.14363\n",
      "[80]\tvalid_0's multi_logloss: 1.14319\n",
      "[81]\tvalid_0's multi_logloss: 1.14284\n",
      "[82]\tvalid_0's multi_logloss: 1.14235\n",
      "[83]\tvalid_0's multi_logloss: 1.1419\n",
      "[84]\tvalid_0's multi_logloss: 1.14135\n",
      "[85]\tvalid_0's multi_logloss: 1.14107\n",
      "[86]\tvalid_0's multi_logloss: 1.14067\n",
      "[87]\tvalid_0's multi_logloss: 1.14015\n",
      "[88]\tvalid_0's multi_logloss: 1.13974\n",
      "[89]\tvalid_0's multi_logloss: 1.13937\n",
      "[90]\tvalid_0's multi_logloss: 1.13901\n",
      "[91]\tvalid_0's multi_logloss: 1.13856\n",
      "[92]\tvalid_0's multi_logloss: 1.13828\n",
      "[93]\tvalid_0's multi_logloss: 1.13783\n",
      "[94]\tvalid_0's multi_logloss: 1.13741\n",
      "[95]\tvalid_0's multi_logloss: 1.137\n",
      "[96]\tvalid_0's multi_logloss: 1.13652\n",
      "[97]\tvalid_0's multi_logloss: 1.13621\n",
      "[98]\tvalid_0's multi_logloss: 1.13596\n",
      "[99]\tvalid_0's multi_logloss: 1.13542\n",
      "[100]\tvalid_0's multi_logloss: 1.13521\n"
     ]
    }
   ],
   "source": [
    "default_lgbc.fit(X = X_train_split, y = Y_train_split, eval_set=[(X_valid,Y_valid)]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.6238\n",
      "Recall: 0.6380\n",
      "f1-score: 0.5929\n"
     ]
    }
   ],
   "source": [
    "check_model(default_lgbc.predict(X_test_vect), Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fitting without validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n",
       "        importance_type='split', learning_rate=0.1, max_depth=-1,\n",
       "        min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,\n",
       "        n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,\n",
       "        random_state=None, reg_alpha=0.0, reg_lambda=0.0, silent=True,\n",
       "        subsample=1.0, subsample_for_bin=200000, subsample_freq=0)"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "default_lgbc.fit(X = X_train_vect, y = Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.6314\n",
      "Recall: 0.6481\n",
      "f1-score: 0.6082\n"
     ]
    }
   ],
   "source": [
    "check_model(default_lgbc.predict(X_test_vect),Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#learning rate (default = 0.1) - small with large num_iterations\n",
    "#n_estimators (default =100) - large\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "from  sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'learning_rate':[0.1, 0.05, 0.01],\n",
    "              'n_estimators':[100,200,300]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = GridSearchCV(estimator=default_lgbc, param_grid = param_grid )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#grid = RandomizedSearchCV(svc_pipeline, param_grid, n_iter=10, scoring='f1_macro', cv=skf, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/friday/anaconda3/envs/boringname/lib/python3.6/site-packages/sklearn/model_selection/_split.py:1943: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "grid_model = grid.fit(X = X_train_vect, y = Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 0.05, 'n_estimators': 200}"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_model.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.6253\n",
      "Recall: 0.6461\n",
      "f1-score: 0.6049\n"
     ]
    }
   ],
   "source": [
    "\n",
    "check_model(grid_model.predict(X_test_vect),Y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
